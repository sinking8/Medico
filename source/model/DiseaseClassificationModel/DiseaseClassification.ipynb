{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "data_set_dir = os.getcwd()+\"//Dataset\"\n",
    "train_dir = \"//training.csv\"\n",
    "test_dir   = \"//testing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Test Data####\n",
    "test_data = pd.DataFrame(pd.read_csv(data_set_dir+test_dir))\n",
    "X_test = test_data.drop(\"prognosis\",axis=1).values\n",
    "y_test = test_data['prognosis']\n",
    "#print(test_data.head(2))\n",
    "#print(test_x.shape)\n",
    "#print(test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Data**<br>\n",
    "\n",
    "itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
    "0        1          1                     1                    0          0   \n",
    "1        0          0                     0                    1          1   \n",
    "\n",
    "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
    "0       0           0             0        0                 0  ...   \n",
    "1       1           0             0        0                 0  ...   \n",
    "\n",
    "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
    "0           0         0             0                    0   \n",
    "1           0         0             0                    0   \n",
    "\n",
    "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
    "0                     0                   0        0                     0   \n",
    "1                     0                   0        0                     0   \n",
    "\n",
    "   yellow_crust_ooze         prognosis  \n",
    "0                  0  Fungal infection  \n",
    "1                  0           Allergy  \n",
    "\n",
    "[2 rows x 133 columns]\n",
    "<br><br><br>\n",
    "**X_Test Shape :**  (41, 132)<br>\n",
    "**Y_Test Shape :**  (41,)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training Data ##\n",
    "train_data = pd.DataFrame(pd.read_csv(data_set_dir+train_dir))\n",
    "#print(train_data.head(1))\n",
    "#training set \n",
    "X_train= train_data.drop(\"prognosis\",axis=1).values\n",
    "y_train = train_data['prognosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train shape :  (4920, 132)\n",
      "[[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_train_unique = y_train.unique()\n",
    "#print(y_train.shape)\n",
    "#print(\"y_Train :\",y_train.unique())\n",
    "#print(\"y_Train_unique\",y_train_unique.shape)\n",
    "print(\"X Train shape : \",X_train.shape)\n",
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X_Train shape :  (4920, 132)**<br>\n",
    "\n",
    "**y_Train** : ['Fungal infection' 'Allergy' 'GERD' 'Chronic cholestasis' 'Drug Reaction'\n",
    " 'Peptic ulcer diseae' 'AIDS' 'Diabetes ' 'Gastroenteritis'\n",
    " 'Bronchial Asthma' 'Hypertension ' 'Migraine' 'Cervical spondylosis'\n",
    " 'Paralysis (brain hemorrhage)' 'Jaundice' 'Malaria' 'Chicken pox'\n",
    " 'Dengue' 'Typhoid' 'hepatitis A' 'Hepatitis B' 'Hepatitis C'\n",
    " 'Hepatitis D' 'Hepatitis E' 'Alcoholic hepatitis' 'Tuberculosis'\n",
    " 'Common Cold' 'Pneumonia' 'Dimorphic hemmorhoids(piles)' 'Heart attack'\n",
    " 'Varicose veins' 'Hypothyroidism' 'Hyperthyroidism' 'Hypoglycemia'\n",
    " 'Osteoarthristis' 'Arthritis' '(vertigo) Paroymsal  Positional Vertigo'\n",
    " 'Acne' 'Urinary tract infection' 'Psoriasis' 'Impetigo']<br>\n",
    "**y_train_unique shape** =  (41,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15  4 16  9 14 33  1 12 17  6 23 30  7 32 28 29  8 11 37 40 19 20 21 22\n",
      "  3 36 10 34 13 18 39 26 24 25 31  5  0  2 38 35 27]\n",
      "(41,)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_unique_encoded = label_encoder.fit_transform(y_train_unique)\n",
    "y_dict = {}\n",
    "for i in range(len(y_train_unique)):\n",
    "    y_dict[y_train_unique[i]] = y_train_unique_encoded[i]\n",
    "    \n",
    "#print(Y_dict)\n",
    "##Label Encoding train_Y\n",
    "le = label_encoder.fit(y_train)\n",
    "y_train_encoded = le.transform(y_train)\n",
    "y_train_encoded = np.ravel(y_train_encoded)\n",
    "##Label Encoding test_Y\n",
    "y_test_encoded  =le.transform(y_test)\n",
    "y_test_encoded = np.ravel(y_test_encoded)\n",
    "print(y_test_encoded)\n",
    "print(y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Encoded Y**\n",
    "\n",
    "{'Fungal infection': 15, 'Allergy': 4, 'GERD': 16, 'Chronic cholestasis': 9, 'Drug Reaction': 14, 'Peptic ulcer diseae': 33, 'AIDS': 1, 'Diabetes ': 12, 'Gastroenteritis': 17, 'Bronchial Asthma': 6, 'Hypertension ': 23, 'Migraine': 30, 'Cervical spondylosis': 7, 'Paralysis (brain hemorrhage)': 32, 'Jaundice': 28, 'Malaria': 29, 'Chicken pox': 8, 'Dengue': 11, 'Typhoid': 37, 'hepatitis A': 40, 'Hepatitis B': 19, 'Hepatitis C': 20, 'Hepatitis D': 21, 'Hepatitis E': 22, 'Alcoholic hepatitis': 3, 'Tuberculosis': 36, 'Common Cold': 10, 'Pneumonia': 34, 'Dimorphic hemmorhoids(piles)': 13, 'Heart attack': 18, 'Varicose veins': 39, 'Hypothyroidism': 26, 'Hyperthyroidism': 24, 'Hypoglycemia': 25, 'Osteoarthristis': 31, 'Arthritis': 5, '(vertigo) Paroymsal  Positional Vertigo': 0, 'Acne': 2, 'Urinary tract infection': 38, 'Psoriasis': 35, 'Impetigo': 27}m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=132,activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(units=10,activation='relu'))\n",
    "\n",
    "model.add(Dense(units =41,activation='softmax'))\n",
    "##Classification --> categorical cross entropy\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##EarlyStopping to prevent OverFitting \n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 4920 samples, validate on 41 samples\n",
      "Epoch 1/600\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "4920/4920 [==============================] - 0s 100us/sample - loss: 3.0426 - val_loss: 1.7732\n",
      "Epoch 2/600\n",
      "4920/4920 [==============================] - 0s 47us/sample - loss: 1.2169 - val_loss: 0.3057\n",
      "Epoch 3/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.3942 - val_loss: 0.0595\n",
      "Epoch 4/600\n",
      "4920/4920 [==============================] - 0s 47us/sample - loss: 0.1928 - val_loss: 0.0178\n",
      "Epoch 5/600\n",
      "4920/4920 [==============================] - 0s 50us/sample - loss: 0.1148 - val_loss: 0.0064\n",
      "Epoch 6/600\n",
      "4920/4920 [==============================] - 0s 48us/sample - loss: 0.0789 - val_loss: 0.0032\n",
      "Epoch 7/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0609 - val_loss: 0.0017\n",
      "Epoch 8/600\n",
      "4920/4920 [==============================] - 0s 49us/sample - loss: 0.0496 - val_loss: 9.3183e-04\n",
      "Epoch 9/600\n",
      "4920/4920 [==============================] - 0s 49us/sample - loss: 0.0387 - val_loss: 5.9136e-04\n",
      "Epoch 10/600\n",
      "4920/4920 [==============================] - 0s 49us/sample - loss: 0.0331 - val_loss: 3.9511e-04\n",
      "Epoch 11/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0292 - val_loss: 2.3649e-04\n",
      "Epoch 12/600\n",
      "4920/4920 [==============================] - 0s 47us/sample - loss: 0.0246 - val_loss: 1.6402e-04\n",
      "Epoch 13/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0234 - val_loss: 1.0763e-04\n",
      "Epoch 14/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0188 - val_loss: 7.3343e-05\n",
      "Epoch 15/600\n",
      "4920/4920 [==============================] - 0s 48us/sample - loss: 0.0159 - val_loss: 6.4844e-05\n",
      "Epoch 16/600\n",
      "4920/4920 [==============================] - 0s 49us/sample - loss: 0.0167 - val_loss: 4.7382e-05\n",
      "Epoch 17/600\n",
      "4920/4920 [==============================] - 0s 50us/sample - loss: 0.0159 - val_loss: 3.1914e-05\n",
      "Epoch 18/600\n",
      "4920/4920 [==============================] - 0s 49us/sample - loss: 0.0143 - val_loss: 2.7669e-05\n",
      "Epoch 19/600\n",
      "4920/4920 [==============================] - 0s 49us/sample - loss: 0.0133 - val_loss: 1.9654e-05\n",
      "Epoch 20/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0114 - val_loss: 1.9189e-05\n",
      "Epoch 21/600\n",
      "4920/4920 [==============================] - 0s 51us/sample - loss: 0.0118 - val_loss: 1.5037e-05\n",
      "Epoch 22/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0096 - val_loss: 1.0728e-05\n",
      "Epoch 23/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0095 - val_loss: 8.1788e-06\n",
      "Epoch 24/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0088 - val_loss: 6.5128e-06\n",
      "Epoch 25/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0090 - val_loss: 6.6117e-06\n",
      "Epoch 26/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0086 - val_loss: 5.3556e-06\n",
      "Epoch 27/600\n",
      "4920/4920 [==============================] - 0s 47us/sample - loss: 0.0083 - val_loss: 2.7389e-06\n",
      "Epoch 28/600\n",
      "4920/4920 [==============================] - 0s 51us/sample - loss: 0.0071 - val_loss: 3.8583e-06\n",
      "Epoch 29/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0085 - val_loss: 1.9946e-06\n",
      "Epoch 30/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0068 - val_loss: 1.5265e-06\n",
      "Epoch 31/600\n",
      "4920/4920 [==============================] - 0s 52us/sample - loss: 0.0059 - val_loss: 3.1924e-06\n",
      "Epoch 32/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0058 - val_loss: 2.1050e-06\n",
      "Epoch 33/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0077 - val_loss: 1.4305e-06\n",
      "Epoch 34/600\n",
      "4920/4920 [==============================] - 0s 50us/sample - loss: 0.0068 - val_loss: 1.1892e-06\n",
      "Epoch 35/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0063 - val_loss: 2.0323e-06\n",
      "Epoch 36/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0060 - val_loss: 8.7808e-07\n",
      "Epoch 37/600\n",
      "4920/4920 [==============================] - 0s 49us/sample - loss: 0.0048 - val_loss: 9.0133e-07\n",
      "Epoch 38/600\n",
      "4920/4920 [==============================] - 0s 47us/sample - loss: 0.0057 - val_loss: 6.6292e-07\n",
      "Epoch 39/600\n",
      "4920/4920 [==============================] - 0s 51us/sample - loss: 0.0051 - val_loss: 8.1993e-07\n",
      "Epoch 40/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0047 - val_loss: 5.7860e-07\n",
      "Epoch 41/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0056 - val_loss: 3.4600e-07\n",
      "Epoch 42/600\n",
      "4920/4920 [==============================] - 0s 57us/sample - loss: 0.0059 - val_loss: 3.6053e-07\n",
      "Epoch 43/600\n",
      "4920/4920 [==============================] - 0s 47us/sample - loss: 0.0039 - val_loss: 4.8556e-07\n",
      "Epoch 44/600\n",
      "4920/4920 [==============================] - 0s 51us/sample - loss: 0.0043 - val_loss: 2.7040e-07\n",
      "Epoch 45/600\n",
      "4920/4920 [==============================] - 0s 51us/sample - loss: 0.0049 - val_loss: 4.3322e-07\n",
      "Epoch 46/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0046 - val_loss: 5.3208e-07\n",
      "Epoch 47/600\n",
      "4920/4920 [==============================] - 0s 51us/sample - loss: 0.0041 - val_loss: 1.7445e-07\n",
      "Epoch 48/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0044 - val_loss: 5.1463e-07\n",
      "Epoch 49/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0042 - val_loss: 6.3966e-08\n",
      "Epoch 50/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0040 - val_loss: 8.1411e-08\n",
      "Epoch 51/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0037 - val_loss: 1.5701e-07\n",
      "Epoch 52/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0037 - val_loss: 1.0176e-07\n",
      "Epoch 53/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0044 - val_loss: 2.5586e-07\n",
      "Epoch 54/600\n",
      "4920/4920 [==============================] - 0s 47us/sample - loss: 0.0037 - val_loss: 6.9781e-08\n",
      "Epoch 55/600\n",
      "4920/4920 [==============================] - 0s 49us/sample - loss: 0.0037 - val_loss: 1.7736e-07\n",
      "Epoch 56/600\n",
      "4920/4920 [==============================] - 0s 46us/sample - loss: 0.0027 - val_loss: 1.4538e-07\n",
      "Epoch 57/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0039 - val_loss: 4.0706e-08\n",
      "Epoch 58/600\n",
      "4920/4920 [==============================] - 0s 42us/sample - loss: 0.0043 - val_loss: 2.9075e-08\n",
      "Epoch 59/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0033 - val_loss: 1.7445e-08\n",
      "Epoch 60/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0032 - val_loss: 4.0706e-08\n",
      "Epoch 61/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0048 - val_loss: 7.5596e-08\n",
      "Epoch 62/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0042 - val_loss: 1.9771e-07\n",
      "Epoch 63/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0027 - val_loss: 3.1983e-08\n",
      "Epoch 64/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0037 - val_loss: 1.4538e-08\n",
      "Epoch 65/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0023 - val_loss: 1.1630e-08\n",
      "Epoch 66/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0025 - val_loss: 2.0353e-08\n",
      "Epoch 67/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0026 - val_loss: 5.8151e-09\n",
      "Epoch 68/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0027 - val_loss: 4.3613e-08\n",
      "Epoch 69/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0023 - val_loss: 1.7445e-08\n",
      "Epoch 70/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4920/4920 [==============================] - 0s 42us/sample - loss: 0.0026 - val_loss: 2.3260e-08\n",
      "Epoch 71/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0031 - val_loss: 1.1630e-08\n",
      "Epoch 72/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0024 - val_loss: 2.0353e-08\n",
      "Epoch 73/600\n",
      "4920/4920 [==============================] - 0s 50us/sample - loss: 0.0016 - val_loss: 1.4538e-08\n",
      "Epoch 74/600\n",
      "4920/4920 [==============================] - 0s 48us/sample - loss: 0.0021 - val_loss: 1.4538e-08\n",
      "Epoch 75/600\n",
      "4920/4920 [==============================] - 0s 47us/sample - loss: 0.0030 - val_loss: 1.7445e-08\n",
      "Epoch 76/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0024 - val_loss: 2.9075e-09\n",
      "Epoch 77/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0022 - val_loss: 2.9075e-09\n",
      "Epoch 78/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0023 - val_loss: 0.0000e+00\n",
      "Epoch 79/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0020 - val_loss: 1.7445e-08\n",
      "Epoch 80/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0031 - val_loss: 5.8151e-09\n",
      "Epoch 81/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0023 - val_loss: 0.0000e+00\n",
      "Epoch 82/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0023 - val_loss: 2.9075e-09\n",
      "Epoch 83/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0013 - val_loss: 0.0000e+00\n",
      "Epoch 84/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0015 - val_loss: 2.9075e-09\n",
      "Epoch 85/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0028 - val_loss: 2.9075e-09\n",
      "Epoch 86/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0022 - val_loss: 1.4538e-08\n",
      "Epoch 87/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0033 - val_loss: 5.8151e-09\n",
      "Epoch 88/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0030 - val_loss: 8.7226e-09\n",
      "Epoch 89/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0020 - val_loss: 2.9075e-09\n",
      "Epoch 90/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0026 - val_loss: 5.8151e-09\n",
      "Epoch 91/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0034 - val_loss: 5.8151e-09\n",
      "Epoch 92/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0016 - val_loss: 0.0000e+00\n",
      "Epoch 93/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0016 - val_loss: 0.0000e+00\n",
      "Epoch 94/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0020 - val_loss: 0.0000e+00\n",
      "Epoch 95/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0013 - val_loss: 0.0000e+00\n",
      "Epoch 96/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0022 - val_loss: 2.9075e-09\n",
      "Epoch 97/600\n",
      "4920/4920 [==============================] - 0s 45us/sample - loss: 0.0026 - val_loss: 1.7445e-08\n",
      "Epoch 98/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0020 - val_loss: 5.8151e-09\n",
      "Epoch 99/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0015 - val_loss: 2.9075e-09\n",
      "Epoch 100/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0013 - val_loss: 0.0000e+00\n",
      "Epoch 101/600\n",
      "4920/4920 [==============================] - 0s 52us/sample - loss: 0.0021 - val_loss: 0.0000e+00\n",
      "Epoch 102/600\n",
      "4920/4920 [==============================] - 0s 44us/sample - loss: 0.0013 - val_loss: 0.0000e+00\n",
      "Epoch 103/600\n",
      "4920/4920 [==============================] - 0s 43us/sample - loss: 0.0016 - val_loss: 0.0000e+00\n",
      "Epoch 00103: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25e77427358>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train_encoded, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test_encoded), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25e774fa550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[3])\n",
    "test = np.reshape(X_test[3],(1,132))\n",
    "predictions = model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(y_test_encoded[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [41, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-09841bb8bb94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_encoded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \"\"\"\n\u001b[0;32m   1966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [41, 1]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_encoded,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
